{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us predict who is earning more than 50.000 dollar.\n",
    "Those people will be eligible to stay at our XXX lounge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from shap.datasets import adult  # shap is only used as dataset utility\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y_true = adult()\n",
    "X.columns = [col.lower() for col in X.columns]\n",
    "X.head()\n",
    "\n",
    "# split train test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairtalk.plots import plot_perc_true_sex\n",
    "\n",
    "y_true = y_true * 1 \n",
    "sex = X['sex'].apply(lambda sex: \"female\" if sex == 0 else \"male\")\n",
    "\n",
    "plot_perc_true_sex(y_true, sex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit an unaware model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "numeric_columns = ['age', 'capital gain', 'education-num', 'capital loss', 'hours per week']\n",
    "\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X[numeric_columns], y_true)\n",
    "\n",
    "y_pred = classifier.predict(X[numeric_columns])\n",
    "y_prob = classifier.predict_proba(X[numeric_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairlearn.metrics import group_summary\n",
    "from sklearn.metrics import accuracy_score\n",
    "group_summary(accuracy_score, y_true, y_pred, sensitive_features=sex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairlearn.metrics import selection_rate, ratio_from_summary\n",
    "selection_rate_summary = group_summary(selection_rate, y_true, y_pred, sensitive_features=sex)\n",
    "selection_rate_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_from_summary(selection_rate_summary)\n",
    "# Thus one group is twice as much selected as the other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairlearn.metrics import equalized_odds_difference, equalized_odds_ratio\n",
    "# Thus the probability barely of true positive and false negative barely changes if the protetected attribute \n",
    "# changes value\n",
    "\n",
    "eo_diff = equalized_odds_difference(y_true, y_pred, sensitive_features=sex)\n",
    "eo_ratio = equalized_odds_ratio(y_true, y_pred, sensitive_features=sex)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairlearn.metrics import equalized_odds_ratio\n",
    "equalized_odds_ratio(y_true, y_pred, sensitive_features=sex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairlearn.metrics import true_positive_rate, false_positive_rate\n",
    "from fairtalk.summary import flatten_group_summary\n",
    "\n",
    "tp = group_summary(true_positive_rate, y_true, y_pred, sensitive_features=sex)\n",
    "fp = group_summary(false_positive_rate, y_true, y_pred, sensitive_features=sex)\n",
    "\n",
    "pd.DataFrame([\n",
    "    flatten_group_summary(tp),\n",
    "    flatten_group_summary(fp)\n",
    "], index=['tp', 'fp']).assign(ratio = lambda x: x['female'] / x['male'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_from_summary(tp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy (TP + TN)/ All: The model is better at assesing most appropriate category of women\n",
    "# Balanced accuracy: If the smallest category (positive) gets more weight, weighed accuracy approx the same\n",
    "# Precision TP/ (TP + FP): More women (+/- 50%) vs men (+/- 25%) are wrongly chosen for the True category\n",
    "# Recall TP/ (TP + FN): More women are forgot\n",
    "# Selection rate (TP + FP)/ P: Men are twice as likely to be selected\n",
    "\n",
    "from fairlearn.widget import FairlearnDashboard\n",
    "FairlearnDashboard(sensitive_features=sex,\n",
    "                   sensitive_feature_names=['sex'],\n",
    "                   y_true=y_true,\n",
    "                   y_pred={\"initial model\": y_pred})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mitigate disparity using postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairlearn.postprocessing import ThresholdOptimizer\n",
    "from sklearn import clone\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "from sklearn.exceptions import NotFittedError\n",
    "\n",
    "\n",
    "class LogisticRegressionAsRegression(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, logistic_regression_estimator):\n",
    "        self.logistic_regression_estimator = logistic_regression_estimator\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        try:\n",
    "            check_is_fitted(self.logistic_regression_estimator)\n",
    "            self.logistic_regression_estimator_ = self.logistic_regression_estimator\n",
    "        except NotFittedError:\n",
    "            self.logistic_regression_estimator_ = clone(\n",
    "                self.logistic_regression_estimator\n",
    "            ).fit(X, y)\n",
    "        return self\n",
    "    def predict(self, X):\n",
    "        # use predict_proba to get real values instead of 0/1, select only prob for 1\n",
    "        scores = self.logistic_regression_estimator_.predict_proba(X)[:, 1]\n",
    "        return scores\n",
    "\n",
    "\n",
    "estimator_wrapper = LogisticRegressionAsRegression(classifier).fit(X[numeric_columns], y_true)\n",
    "\n",
    "postprocessed_predictor_DP = ThresholdOptimizer(\n",
    "    estimator=estimator_wrapper, constraints=\"demographic_parity\", prefit=True\n",
    ")\n",
    "\n",
    "postprocessed_predictor_DP.fit(\n",
    "    X[numeric_columns], y_true, sensitive_features=sex\n",
    ")\n",
    "\n",
    "fairness_aware_predictions_DP_train = postprocessed_predictor_DP.predict(\n",
    "    X[numeric_columns], sensitive_features=sex\n",
    ")\n",
    "# fairness_aware_predictions_EO_test = postprocessed_predictor_EO.predict(\n",
    "#     X_test, sensitive_features=sensitive_features_test\n",
    "# )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FairlearnDashboard(sensitive_features=sex,\n",
    "                   sensitive_feature_names=['sex'],\n",
    "                   y_true=y_true,\n",
    "                   y_pred={\n",
    "                       \"initial model\": y_pred, \n",
    "                       \"mitigated_model\": fairness_aware_predictions_DP_train\n",
    "                          })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps of theshold optimizer postprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute the ROC charts per group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairlearn.postprocessing._threshold_optimizer import _reformat_and_group_data\n",
    "from fairtalk.plots import get_roc_points, plot_roc, plot_convex_hull_interpolation, plot_overall_tradeoff\n",
    "from fairtalk.plots import plot_creation_convex_hull\n",
    "\n",
    "data_grouped_by_sensitive_feature = _reformat_and_group_data(sex, y_true, y_prob[:,1])\n",
    "roc_points = get_roc_points(data_grouped_by_sensitive_feature)\n",
    "plt1 = plot_roc(data_grouped_by_sensitive_feature, roc_points)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a lower threshold (operation) we will have more false positives (x) and true positives (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    roc_points\n",
    "    .get('male')\n",
    "    .rename(columns={\"x\": \"False positives\", \"y\": \"True positives\"})\n",
    "    .head(n=5)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the classifications (true and false positives/ negatives), we can calculate the the selection rate and error (1 - accuracy) for each group.\n",
    "\n",
    "\n",
    "Then, we can determine the convex Hull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_creation_convex_hull(sex, y_true, y_prob[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subsequently, we interpolate the convex hull with a grid a of m selection rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_convex_hull_interpolation(sex, y_true, y_prob[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us a dictionary with which operations/ thresholds we can achieve a certain selection rate/ error for each group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trade off plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We pick a selection rate for which the weighted sum of errors is minimal. Thus\n",
    "different groups will have different thresholds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_overall_tradeoff(sex, y_true, y_prob[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to obtain same selection rate for all groups, \n",
    "the base predictions are reweighted based on the threshold neighbours of the selection rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (\n",
    "    group,\n",
    "    interpolation,\n",
    ") in postprocessed_predictor_DP._post_processed_predictor_by_sensitive_feature.items():\n",
    "    print(\"{}:\".format(group))\n",
    "    print(\"\\n \".join(interpolation.__repr__().split(\",\")))\n",
    "    print(\"-----------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
